{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8fa9798",
   "metadata": {},
   "source": [
    "# Atividade 2 - Reconhecimento Facial com DeepFace\n",
    "## Visão Computacional - UC04\n",
    "\n",
    "**Objetivos:**\n",
    "- Carregar imagens e realizar conversões necessárias (BGR↔RGB)\n",
    "- Executar DeepFace.analyze para obter atributos (emoções, idade, gênero, raça)\n",
    "- Destacar rostos com retângulos usando cv2.rectangle\n",
    "- Exibir resultados com matplotlib\n",
    "- Registrar observações sobre confiabilidade e limitações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffe493a",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas Necessárias\n",
    "\n",
    "Primeiro, vamos importar todas as bibliotecas que serão utilizadas no projeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7867d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas principais\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from deepface import DeepFace\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Configurações para melhor visualização\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "print(f\"OpenCV versão: {cv2.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50846d2e",
   "metadata": {},
   "source": [
    "## 2. Funções Utilitárias\n",
    "\n",
    "Vamos criar funções auxiliares para carregar imagens, converter cores e exibir resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d27f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imagem(caminho):\n",
    "    \"\"\"\n",
    "    Carrega uma imagem do disco e converte BGR para RGB\n",
    "    \"\"\"\n",
    "    if not os.path.exists(caminho):\n",
    "        raise FileNotFoundError(f\"Imagem não encontrada: {caminho}\")\n",
    "    \n",
    "    # Carrega imagem em BGR (padrão OpenCV)\n",
    "    img_bgr = cv2.imread(caminho)\n",
    "    if img_bgr is None:\n",
    "        raise Exception(f\"Erro ao carregar imagem: {caminho}\")\n",
    "    \n",
    "    # Converte BGR para RGB para exibição correta no matplotlib\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    return img_rgb, img_bgr\n",
    "\n",
    "def redimensionar_imagem(imagem, largura_max=800):\n",
    "    \"\"\"\n",
    "    Redimensiona imagem mantendo proporção\n",
    "    \"\"\"\n",
    "    altura, largura = imagem.shape[:2]\n",
    "    if largura > largura_max:\n",
    "        proporcao = largura_max / largura\n",
    "        nova_largura = largura_max\n",
    "        nova_altura = int(altura * proporcao)\n",
    "        return cv2.resize(imagem, (nova_largura, nova_altura))\n",
    "    return imagem\n",
    "\n",
    "def criar_imagem_exemplo():\n",
    "    \"\"\"\n",
    "    Cria uma imagem simples para teste caso não haja imagens disponíveis\n",
    "    \"\"\"\n",
    "    # Cria uma imagem com rosto simples\n",
    "    img = np.ones((400, 400, 3), dtype=np.uint8) * 240\n",
    "    \n",
    "    # Desenha um rosto básico\n",
    "    cv2.circle(img, (200, 200), 80, (220, 180, 140), -1)  # Face\n",
    "    cv2.circle(img, (180, 180), 8, (0, 0, 0), -1)  # Olho esquerdo\n",
    "    cv2.circle(img, (220, 180), 8, (0, 0, 0), -1)  # Olho direito\n",
    "    cv2.ellipse(img, (200, 220), (20, 10), 0, 0, 180, (0, 0, 0), 2)  # Boca\n",
    "    \n",
    "    return img\n",
    "\n",
    "print(\"Funções utilitárias definidas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3095197",
   "metadata": {},
   "source": [
    "## 3. Carregamento e Preparação da Imagem\n",
    "\n",
    "Vamos carregar uma imagem para análise. Se não houver imagens na pasta, criaremos uma de exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procura por imagens na pasta\n",
    "pasta_imagens = \"imagens\"\n",
    "extensoes = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "\n",
    "imagens_encontradas = []\n",
    "if os.path.exists(pasta_imagens):\n",
    "    for ext in extensoes:\n",
    "        imagens_encontradas.extend(Path(pasta_imagens).glob(f'*{ext}'))\n",
    "        imagens_encontradas.extend(Path(pasta_imagens).glob(f'*{ext.upper()}'))\n",
    "\n",
    "if imagens_encontradas:\n",
    "    # Usa a primeira imagem encontrada\n",
    "    caminho_imagem = str(imagens_encontradas[0])\n",
    "    print(f\"Carregando imagem: {caminho_imagem}\")\n",
    "    \n",
    "    # Carrega e converte imagem\n",
    "    img_rgb, img_bgr = carregar_imagem(caminho_imagem)\n",
    "    img_rgb = redimensionar_imagem(img_rgb)\n",
    "    img_bgr = redimensionar_imagem(img_bgr)\n",
    "    \n",
    "else:\n",
    "    print(\"Nenhuma imagem encontrada. Criando imagem de exemplo...\")\n",
    "    # Cria imagem de exemplo\n",
    "    img_rgb = criar_imagem_exemplo()\n",
    "    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Salva imagem de exemplo\n",
    "    os.makedirs(pasta_imagens, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(pasta_imagens, 'exemplo.jpg'), img_bgr)\n",
    "    caminho_imagem = os.path.join(pasta_imagens, 'exemplo.jpg')\n",
    "\n",
    "# Exibe informações da imagem\n",
    "print(f\"Dimensões da imagem: {img_rgb.shape}\")\n",
    "print(f\"Tipo de dados: {img_rgb.dtype}\")\n",
    "\n",
    "# Visualiza a imagem original\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Imagem Original')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8893c5",
   "metadata": {},
   "source": [
    "## 4. Análise Facial com DeepFace\n",
    "\n",
    "Agora vamos usar o DeepFace para analisar os rostos na imagem, extraindo informações sobre emoções, idade, gênero e raça:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185c023e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(\"Iniciando análise facial com DeepFace...\")\n",
    "    print(\"Isso pode demorar alguns minutos na primeira execução (download de modelos)...\")\n",
    "    \n",
    "    # Executa análise completa com DeepFace\n",
    "    resultados = DeepFace.analyze(\n",
    "        img_path=caminho_imagem,\n",
    "        actions=['age', 'gender', 'race', 'emotion'],\n",
    "        enforce_detection=False  # Permite análise mesmo se não detectar face claramente\n",
    "    )\n",
    "    \n",
    "    print(\"Análise concluída com sucesso!\")\n",
    "    \n",
    "    # Se há apenas um rosto, converte para lista\n",
    "    if not isinstance(resultados, list):\n",
    "        resultados = [resultados]\n",
    "    \n",
    "    print(f\"Número de rostos detectados: {len(resultados)}\")\n",
    "    \n",
    "    # Exibe resultados detalhados para cada rosto\n",
    "    for i, resultado in enumerate(resultados):\n",
    "        print(f\"\\n--- Rosto {i+1} ---\")\n",
    "        \n",
    "        # Idade\n",
    "        idade = resultado['age']\n",
    "        print(f\"Idade estimada: {idade} anos\")\n",
    "        \n",
    "        # Gênero\n",
    "        genero_info = resultado['gender']\n",
    "        genero_dominante = resultado['dominant_gender']\n",
    "        confianca_genero = genero_info[genero_dominante]\n",
    "        print(f\"Gênero: {genero_dominante} (confiança: {confianca_genero:.1f}%)\")\n",
    "        \n",
    "        # Emoção\n",
    "        emocao_info = resultado['emotion']\n",
    "        emocao_dominante = resultado['dominant_emotion']\n",
    "        confianca_emocao = emocao_info[emocao_dominante]\n",
    "        print(f\"Emoção: {emocao_dominante} (confiança: {confianca_emocao:.1f}%)\")\n",
    "        \n",
    "        # Raça/Etnia\n",
    "        raca_info = resultado['race']\n",
    "        raca_dominante = resultado['dominant_race']\n",
    "        confianca_raca = raca_info[raca_dominante]\n",
    "        print(f\"Raça/Etnia: {raca_dominante} (confiança: {confianca_raca:.1f}%)\")\n",
    "        \n",
    "        # Região do rosto\n",
    "        regiao = resultado['region']\n",
    "        print(f\"Região do rosto: x={regiao['x']}, y={regiao['y']}, w={regiao['w']}, h={regiao['h']}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro na análise: {str(e)}\")\n",
    "    print(\"Tentando análise alternativa...\")\n",
    "    \n",
    "    # Análise alternativa com parâmetros mais flexíveis\n",
    "    try:\n",
    "        resultados = DeepFace.analyze(\n",
    "            img_path=img_rgb,\n",
    "            actions=['emotion'],\n",
    "            enforce_detection=False\n",
    "        )\n",
    "        if not isinstance(resultados, list):\n",
    "            resultados = [resultados]\n",
    "        print(\"Análise alternativa bem-sucedida!\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Erro na análise alternativa: {str(e2)}\")\n",
    "        resultados = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c53d44",
   "metadata": {},
   "source": [
    "## 5. Visualização dos Resultados\n",
    "\n",
    "Vamos desenhar retângulos ao redor dos rostos detectados e exibir as informações extraídas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838488c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria cópia da imagem para desenhar\n",
    "img_resultado = img_rgb.copy()\n",
    "\n",
    "if resultados:\n",
    "    for i, resultado in enumerate(resultados):\n",
    "        # Extrai coordenadas do rosto\n",
    "        regiao = resultado['region']\n",
    "        x, y, w, h = regiao['x'], regiao['y'], regiao['w'], regiao['h']\n",
    "        \n",
    "        # Desenha retângulo ao redor do rosto\n",
    "        cv2.rectangle(img_resultado, (x, y), (x + w, y + h), (255, 0, 0), 3)\n",
    "        \n",
    "        # Prepara texto com informações\n",
    "        try:\n",
    "            idade = int(resultado['age'])\n",
    "            genero = resultado['dominant_gender']\n",
    "            emocao = resultado['dominant_emotion']\n",
    "            raca = resultado['dominant_race']\n",
    "            \n",
    "            # Traduz emoções para português\n",
    "            traducao_emocoes = {\n",
    "                'angry': 'Raiva',\n",
    "                'disgust': 'Nojo',\n",
    "                'fear': 'Medo',\n",
    "                'happy': 'Feliz',\n",
    "                'sad': 'Triste',\n",
    "                'surprise': 'Surpresa',\n",
    "                'neutral': 'Neutro'\n",
    "            }\n",
    "            \n",
    "            # Traduz gêneros\n",
    "            traducao_generos = {\n",
    "                'Man': 'Homem',\n",
    "                'Woman': 'Mulher'\n",
    "            }\n",
    "            \n",
    "            emocao_pt = traducao_emocoes.get(emocao, emocao)\n",
    "            genero_pt = traducao_generos.get(genero, genero)\n",
    "            \n",
    "            # Lista de textos para exibir\n",
    "            textos = [\n",
    "                f\"Idade: {idade}\",\n",
    "                f\"Genero: {genero_pt}\",\n",
    "                f\"Emocao: {emocao_pt}\",\n",
    "                f\"Raca: {raca}\"\n",
    "            ]\n",
    "            \n",
    "            # Desenha textos\n",
    "            for j, texto in enumerate(textos):\n",
    "                y_texto = y - 10 - (len(textos) - j - 1) * 25\n",
    "                if y_texto < 25:\n",
    "                    y_texto = y + h + 25 + j * 25\n",
    "                \n",
    "                # Fundo branco para o texto\n",
    "                (text_width, text_height), _ = cv2.getTextSize(texto, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(img_resultado, (x, y_texto - text_height - 5), \n",
    "                            (x + text_width + 10, y_texto + 5), (255, 255, 255), -1)\n",
    "                \n",
    "                # Texto em preto\n",
    "                cv2.putText(img_resultado, texto, (x + 5, y_texto), \n",
    "                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)\n",
    "        \n",
    "        except KeyError as e:\n",
    "            print(f\"Chave não encontrada no resultado: {e}\")\n",
    "            # Desenha apenas um rótulo básico\n",
    "            cv2.putText(img_resultado, f\"Rosto {i+1}\", (x, y-10), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "\n",
    "else:\n",
    "    print(\"Nenhum rosto foi detectado para visualização.\")\n",
    "\n",
    "print(\"Visualização preparada!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535db19d",
   "metadata": {},
   "source": [
    "## 6. Exibição Final dos Resultados\n",
    "\n",
    "Vamos exibir a comparação entre a imagem original e a imagem com as análises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria figura com subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Imagem original\n",
    "axes[0].imshow(img_rgb)\n",
    "axes[0].set_title('Imagem Original', fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Imagem com análises\n",
    "axes[1].imshow(img_resultado)\n",
    "title = f'Análise Facial - {len(resultados) if resultados else 0} rosto(s) detectado(s)'\n",
    "axes[1].set_title(title, fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Salva resultado\n",
    "img_resultado_bgr = cv2.cvtColor(img_resultado, cv2.COLOR_RGB2BGR)\n",
    "cv2.imwrite('resultado_analise_facial.jpg', img_resultado_bgr)\n",
    "print(\"Resultado salvo como 'resultado_analise_facial.jpg'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b84adc",
   "metadata": {},
   "source": [
    "## 7. Análise Detalhada dos Resultados\n",
    "\n",
    "Vamos exibir gráficos com as probabilidades de cada atributo detectado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50766f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "if resultados:\n",
    "    for i, resultado in enumerate(resultados):\n",
    "        print(f\"\\n=== ANÁLISE DETALHADA DO ROSTO {i+1} ===\")\n",
    "        \n",
    "        # Cria subplots para gráficos\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle(f'Análise Detalhada - Rosto {i+1}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Gráfico de Emoções\n",
    "        if 'emotion' in resultado:\n",
    "            emocoes = resultado['emotion']\n",
    "            emocoes_pt = {\n",
    "                'angry': 'Raiva',\n",
    "                'disgust': 'Nojo', \n",
    "                'fear': 'Medo',\n",
    "                'happy': 'Feliz',\n",
    "                'sad': 'Triste',\n",
    "                'surprise': 'Surpresa',\n",
    "                'neutral': 'Neutro'\n",
    "            }\n",
    "            \n",
    "            emocoes_traduzidas = {emocoes_pt.get(k, k): v for k, v in emocoes.items()}\n",
    "            \n",
    "            axes[0,0].bar(emocoes_traduzidas.keys(), emocoes_traduzidas.values())\n",
    "            axes[0,0].set_title('Distribuição de Emoções')\n",
    "            axes[0,0].set_ylabel('Probabilidade (%)')\n",
    "            axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Gráfico de Gênero\n",
    "        if 'gender' in resultado:\n",
    "            generos = resultado['gender']\n",
    "            generos_pt = {'Man': 'Homem', 'Woman': 'Mulher'}\n",
    "            generos_traduzidos = {generos_pt.get(k, k): v for k, v in generos.items()}\n",
    "            \n",
    "            axes[0,1].pie(generos_traduzidos.values(), labels=generos_traduzidos.keys(), \n",
    "                         autopct='%1.1f%%', startangle=90)\n",
    "            axes[0,1].set_title('Distribuição de Gênero')\n",
    "        \n",
    "        # Gráfico de Raça/Etnia\n",
    "        if 'race' in resultado:\n",
    "            racas = resultado['race']\n",
    "            axes[1,0].bar(racas.keys(), racas.values())\n",
    "            axes[1,0].set_title('Distribuição de Raça/Etnia')\n",
    "            axes[1,0].set_ylabel('Probabilidade (%)')\n",
    "            axes[1,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Informações gerais\n",
    "        axes[1,1].axis('off')\n",
    "        info_texto = f\"\"\"RESUMO DA ANÁLISE:\n",
    "        \n",
    "Idade estimada: {resultado.get('age', 'N/A')} anos\n",
    "\n",
    "Gênero dominante: {resultado.get('dominant_gender', 'N/A')}\n",
    "Confiança: {resultado.get('gender', {}).get(resultado.get('dominant_gender', ''), 0):.1f}%\n",
    "\n",
    "Emoção dominante: {resultado.get('dominant_emotion', 'N/A')}\n",
    "Confiança: {resultado.get('emotion', {}).get(resultado.get('dominant_emotion', ''), 0):.1f}%\n",
    "\n",
    "Raça/Etnia dominante: {resultado.get('dominant_race', 'N/A')}\n",
    "Confiança: {resultado.get('race', {}).get(resultado.get('dominant_race', ''), 0):.1f}%\n",
    "\n",
    "Posição do rosto:\n",
    "X: {resultado.get('region', {}).get('x', 'N/A')}\n",
    "Y: {resultado.get('region', {}).get('y', 'N/A')}\n",
    "Largura: {resultado.get('region', {}).get('w', 'N/A')}\n",
    "Altura: {resultado.get('region', {}).get('h', 'N/A')}\n",
    "        \"\"\"\n",
    "        \n",
    "        axes[1,1].text(0.1, 0.9, info_texto, transform=axes[1,1].transAxes, \n",
    "                      fontsize=10, verticalalignment='top', \n",
    "                      bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "else:\n",
    "    print(\"Nenhum resultado disponível para análise detalhada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d1bb8",
   "metadata": {},
   "source": [
    "## 8. Conclusão e Observações\n",
    "\n",
    "### Resultados Obtidos\n",
    "\n",
    "Nesta atividade, aplicamos com sucesso técnicas de reconhecimento facial usando a biblioteca DeepFace em conjunto com OpenCV. Os principais resultados incluem:\n",
    "\n",
    "1. **Detecção Facial**: O sistema conseguiu identificar e localizar rostos nas imagens fornecidas\n",
    "2. **Análise de Atributos**: Foram extraídas informações sobre idade, gênero, emoção e raça/etnia\n",
    "3. **Visualização**: Os resultados foram apresentados de forma clara com retângulos destacando os rostos e informações sobrepostas\n",
    "\n",
    "### Observações sobre Confiabilidade\n",
    "\n",
    "**Pontos Fortes:**\n",
    "- O DeepFace utiliza modelos de deep learning pré-treinados que geralmente apresentam boa precisão\n",
    "- A detecção facial funciona bem em condições ideais (boa iluminação, face frontal, alta resolução)\n",
    "- As análises de emoção tendem a ser mais precisas que estimativas de idade\n",
    "\n",
    "**Limitações Observadas:**\n",
    "- **Estimativa de Idade**: Pode apresentar variações significativas, especialmente em idades extremas\n",
    "- **Classificação de Raça**: Baseada em características físicas visíveis, pode não refletir a identidade real da pessoa\n",
    "- **Detecção de Emoções**: Limitada a expressões faciais visíveis, não considera contexto emocional\n",
    "- **Condições da Imagem**: Performance reduzida com má iluminação, ângulos laterais, ou baixa resolução\n",
    "\n",
    "### Considerações Éticas\n",
    "\n",
    "É importante destacar que sistemas de reconhecimento facial levantam questões éticas importantes:\n",
    "- **Privacidade**: O uso deve respeitar o consentimento e privacidade das pessoas\n",
    "- **Viés Algorítmico**: Os modelos podem apresentar vieses baseados nos dados de treinamento\n",
    "- **Aplicação Responsável**: Deve ser usado de forma responsável e transparente\n",
    "\n",
    "### Aplicações Práticas\n",
    "\n",
    "Esta tecnologia tem diversas aplicações positivas:\n",
    "- **Segurança**: Controle de acesso e identificação\n",
    "- **Saúde**: Monitoramento de bem-estar e análise de expressões\n",
    "- **Entretenimento**: Filtros e efeitos em aplicativos\n",
    "- **Pesquisa**: Estudos comportamentais e análise de dados\n",
    "\n",
    "### Conclusão Final\n",
    "\n",
    "O DeepFace mostrou-se uma ferramenta poderosa para análise facial, oferecendo resultados geralmente confiáveis para detecção e classificação de atributos faciais. No entanto, é essencial compreender suas limitações e usar a tecnologia de forma ética e responsável. Os resultados devem sempre ser interpretados considerando o contexto e as limitações inerentes aos modelos de machine learning."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
