{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4c6b1d3",
   "metadata": {},
   "source": [
    "# Atividade 2 - Avaliação e Métricas do Modelo XGBoost\n",
    "\n",
    "**Curso:** Qualificação em IA Industrial  \n",
    "**Unidade Curricular:** Machine Learning  \n",
    "**Objetivo:** Avaliar o desempenho de um modelo XGBoost para predição de atrasos de voos\n",
    "\n",
    "## Objetivo da Atividade\n",
    "Avaliar o desempenho de um modelo XGBoost utilizando métricas avançadas de classificação, incluindo matriz de confusão, curva ROC e AUC.\n",
    "\n",
    "## Contexto do Problema\n",
    "Um grande site de reservas de viagens quer criar um recurso que informe a probabilidade de atraso do voo no momento da reserva, usando dados históricos de voos.\n",
    "\n",
    "### Etapas da Atividade:\n",
    "1. **Importar e preparar os dados**\n",
    "2. **Treinar o modelo XGBoost**\n",
    "3. **Predição do modelo (probabilidades e classes)**\n",
    "4. **Matriz de Confusão**\n",
    "5. **Métricas de desempenho detalhadas**\n",
    "6. **Curva ROC e AUC**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8862f",
   "metadata": {},
   "source": [
    "## 1. Importação das Bibliotecas\n",
    "\n",
    "Importando todas as bibliotecas necessárias para análise, modelagem e visualização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7279e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bibliotecas para machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, accuracy_score,\n",
    "    roc_curve, auc, roc_auc_score, precision_score, recall_score,\n",
    "    f1_score, precision_recall_curve\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Configurações para visualização\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Todas as bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db262467",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Preparação dos Dados\n",
    "\n",
    "Carregando o dataset e preparando os dados para o modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8021c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregamento dos dados\n",
    "df = pd.read_csv('flights_delays_120.csv')\n",
    "\n",
    "print(\"INFORMAÇÕES DO DATASET\")\n",
    "print(f\"Dimensões: {df.shape}\")\n",
    "print(f\"Colunas: {list(df.columns)}\")\n",
    "\n",
    "# Visualizando as primeiras linhas\n",
    "print(\"\\nPrimeiras 5 linhas do dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Informações sobre os dados\n",
    "print(\"\\nInformações gerais:\")\n",
    "print(df.info())\n",
    "\n",
    "# Verificando valores ausentes\n",
    "print(f\"\\nValores ausentes:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf354cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise da variável target\n",
    "print(\"ANÁLISE DA VARIÁVEL TARGET (delayed)\")\n",
    "print(f\"Distribuição da variável 'delayed':\")\n",
    "target_counts = df['delayed'].value_counts()\n",
    "target_prop = df['delayed'].value_counts(normalize=True)\n",
    "\n",
    "for i, (count, prop) in enumerate(zip(target_counts, target_prop)):\n",
    "    label = \"Não Atrasado\" if i == 0 else \"Atrasado\"\n",
    "    print(f\"  {label}: {count} ({prop:.2%})\")\n",
    "\n",
    "# Visualização da distribuição da variável target\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Gráfico de barras - contagem\n",
    "plt.subplot(1, 2, 1)\n",
    "target_counts.plot(kind='bar', color=['skyblue', 'salmon'])\n",
    "plt.title('Distribuição de Atrasos - Contagem')\n",
    "plt.xlabel('Delayed')\n",
    "plt.ylabel('Quantidade')\n",
    "plt.xticks([0, 1], ['Não Atrasado', 'Atrasado'], rotation=0)\n",
    "\n",
    "# Gráfico de pizza - proporção\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(target_counts.values, labels=['Não Atrasado', 'Atrasado'], \n",
    "        autopct='%1.1f%%', colors=['skyblue', 'salmon'])\n",
    "plt.title('Proporção de Atrasos')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906cd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparação dos dados para o modelo\n",
    "print(\"PREPARAÇÃO DOS DADOS\")\n",
    "\n",
    "# Separação de features (X) e target (y)\n",
    "X = df.drop('delayed', axis=1)\n",
    "y = df['delayed']\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "\n",
    "# Tratamento de variáveis categóricas\n",
    "print(f\"\\nVariáveis categóricas encontradas: {X.select_dtypes(include=['object']).columns.tolist()}\")\n",
    "\n",
    "# Convertendo variáveis categóricas em numéricas usando get_dummies\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "print(f\"Dimensões após encoding: {X_encoded.shape}\")\n",
    "print(f\"Novas features criadas: {X_encoded.shape[1] - X.shape[1]}\")\n",
    "\n",
    "# Verificando se há colunas numéricas que precisam de normalização\n",
    "print(f\"\\nTipos de dados após encoding:\")\n",
    "print(X_encoded.dtypes.value_counts())\n",
    "\n",
    "print(f\"\\nPrimeiras colunas após encoding:\")\n",
    "print(list(X_encoded.columns[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão dos dados em treino e teste com estratificação\n",
    "print(\"DIVISÃO DOS DADOS\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_encoded, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  # Garantindo estratificação\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de treinamento: {X_train.shape}\")\n",
    "print(f\"Conjunto de teste: {X_test.shape}\")\n",
    "\n",
    "# Verificando a estratificação\n",
    "print(f\"\\nDistribuição no conjunto de TREINAMENTO:\")\n",
    "train_dist = y_train.value_counts(normalize=True)\n",
    "for i, prop in enumerate(train_dist):\n",
    "    label = \"Não Atrasado\" if i == 0 else \"Atrasado\"\n",
    "    print(f\"  {label}: {prop:.2%}\")\n",
    "\n",
    "print(f\"\\nDistribuição no conjunto de TESTE:\")\n",
    "test_dist = y_test.value_counts(normalize=True)\n",
    "for i, prop in enumerate(test_dist):\n",
    "    label = \"Não Atrasado\" if i == 0 else \"Atrasado\"\n",
    "    print(f\"  {label}: {prop:.2%}\")\n",
    "\n",
    "print(f\"\\nEstratificação mantida com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9dfc9",
   "metadata": {},
   "source": [
    "## 3. Treinamento do Modelo XGBoost\n",
    "\n",
    "Criando e treinando o modelo XGBoost com parâmetros otimizados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673d4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição e treinamento do modelo XGBoost\n",
    "print(\"TREINAMENTO DO MODELO XGBOOST\")\n",
    "\n",
    "# Definindo o classificador XGBoost com parâmetros simples\n",
    "model = XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',  # Métrica de avaliação\n",
    "    n_estimators=100,       # Número de árvores\n",
    "    max_depth=6,            # Profundidade máxima das árvores\n",
    "    learning_rate=0.1       # Taxa de aprendizado\n",
    ")\n",
    "\n",
    "print(f\"Modelo configurado com os seguintes parâmetros:\")\n",
    "for param, value in model.get_params().items():\n",
    "    if param in ['random_state', 'eval_metric', 'n_estimators', 'max_depth', 'learning_rate']:\n",
    "        print(f\"  {param}: {value}\")\n",
    "\n",
    "# Treinamento do modelo\n",
    "print(f\"\\nIniciando treinamento...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(f\"Treinamento concluído com sucesso!\")\n",
    "\n",
    "# Verificando informações do modelo treinado\n",
    "print(f\"\\nInformações do modelo treinado:\")\n",
    "print(f\"Número de features: {model.n_features_in_}\")\n",
    "print(f\"Número de classes: {len(model.classes_)}\")\n",
    "print(f\"Classes: {model.classes_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f0a53",
   "metadata": {},
   "source": [
    "## 4. Predições do Modelo\n",
    "\n",
    "Realizando predições com probabilidades e conversão para classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b82b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizando predições com probabilidades\n",
    "print(\"PREDIÇÕES DO MODELO\")\n",
    "\n",
    "# Obtendo probabilidades para cada classe\n",
    "y_proba = model.predict_proba(X_test)\n",
    "print(f\"Forma das probabilidades: {y_proba.shape}\")\n",
    "print(f\"Colunas: [Prob_Não_Atrasado, Prob_Atrasado]\")\n",
    "\n",
    "# Probabilidades para a classe positiva (atrasado = 1)\n",
    "y_proba_positive = y_proba[:, 1]\n",
    "\n",
    "print(f\"\\nEstatísticas das probabilidades (classe positiva):\")\n",
    "print(f\"Mínima: {y_proba_positive.min():.4f}\")\n",
    "print(f\"Máxima: {y_proba_positive.max():.4f}\")\n",
    "print(f\"Média: {y_proba_positive.mean():.4f}\")\n",
    "print(f\"Mediana: {np.median(y_proba_positive):.4f}\")\n",
    "\n",
    "# Convertendo probabilidades em classes usando threshold 0.5\n",
    "threshold = 0.5\n",
    "y_pred = (y_proba_positive >= threshold).astype(int)\n",
    "\n",
    "print(f\"\\nConversão para classes (threshold = {threshold}):\")\n",
    "print(f\"Predições únicas: {np.unique(y_pred)}\")\n",
    "print(f\"Distribuição das predições:\")\n",
    "pred_counts = pd.Series(y_pred).value_counts()\n",
    "for i, count in enumerate(pred_counts):\n",
    "    label = \"Não Atrasado\" if i == 0 else \"Atrasado\"\n",
    "    print(f\"  {label}: {count}\")\n",
    "\n",
    "# Exemplos de predições\n",
    "print(f\"\\nPrimeiras 10 predições:\")\n",
    "results_df = pd.DataFrame({\n",
    "    'Real': y_test.iloc[:10].values,\n",
    "    'Prob_Atrasado': y_proba_positive[:10],\n",
    "    'Predição': y_pred[:10]\n",
    "})\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d76435",
   "metadata": {},
   "source": [
    "## 5. Matriz de Confusão\n",
    "\n",
    "Calculando e visualizando a matriz de confusão:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bf19ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a matriz de confusão\n",
    "print(\"MATRIZ DE CONFUSÃO\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(cm)\n",
    "\n",
    "# Extraindo os valores TP, TN, FP, FN\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(f\"\\nComponentes da Matriz de Confusão:\")\n",
    "print(f\"True Negatives (TN): {tn}\")\n",
    "print(f\"False Positives (FP): {fp}\")\n",
    "print(f\"False Negatives (FN): {fn}\")\n",
    "print(f\"True Positives (TP): {tp}\")\n",
    "\n",
    "# Visualização da matriz de confusão\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Matriz de confusão simples\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Não Atrasado', 'Atrasado'],\n",
    "            yticklabels=['Não Atrasado', 'Atrasado'])\n",
    "plt.title('Matriz de Confusão - Valores Absolutos')\n",
    "plt.xlabel('Predição')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "# Matriz de confusão normalizada\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=['Não Atrasado', 'Atrasado'],\n",
    "            yticklabels=['Não Atrasado', 'Atrasado'])\n",
    "plt.title('Matriz de Confusão - Normalizada')\n",
    "plt.xlabel('Predição')\n",
    "plt.ylabel('Real')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Interpretação detalhada\n",
    "print(f\"\\nINTERPRETAÇÃO:\")\n",
    "print(f\"• TN ({tn}): Voos corretamente identificados como NÃO atrasados\")\n",
    "print(f\"• FP ({fp}): Voos incorretamente identificados como atrasados (Erro Tipo I)\")\n",
    "print(f\"• FN ({fn}): Voos incorretamente identificados como NÃO atrasados (Erro Tipo II)\")\n",
    "print(f\"• TP ({tp}): Voos corretamente identificados como atrasados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38460c",
   "metadata": {},
   "source": [
    "## 6. Métricas de Desempenho Detalhadas\n",
    "\n",
    "Calculando todas as métricas importantes para avaliação do modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e08e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando métricas de desempenho detalhadas\n",
    "print(\"MÉTRICAS DE DESEMPENHO\")\n",
    "\n",
    "# Métricas calculadas manualmente a partir da matriz de confusão\n",
    "accuracy_manual = (tp + tn) / (tp + tn + fp + fn)\n",
    "sensitivity_recall = tp / (tp + fn)  # Sensibilidade ou Recall\n",
    "specificity = tn / (tn + fp)         # Especificidade\n",
    "precision = tp / (tp + fp)           # Precisão\n",
    "fpr = fp / (fp + tn)                 # Taxa de Falsos Positivos\n",
    "fnr = fn / (fn + tp)                 # Taxa de Falsos Negativos\n",
    "f1 = 2 * (precision * sensitivity_recall) / (precision + sensitivity_recall)\n",
    "\n",
    "print(f\"MÉTRICAS CALCULADAS MANUALMENTE:\")\n",
    "print(f\"Acurácia: {accuracy_manual:.4f} ({accuracy_manual*100:.2f}%)\")\n",
    "print(f\"Sensibilidade (Recall): {sensitivity_recall:.4f} ({sensitivity_recall*100:.2f}%)\")\n",
    "print(f\"Especificidade: {specificity:.4f} ({specificity*100:.2f}%)\")\n",
    "print(f\"Precisão: {precision:.4f} ({precision*100:.2f}%)\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"Taxa de Falsos Positivos (FPR): {fpr:.4f} ({fpr*100:.2f}%)\")\n",
    "print(f\"Taxa de Falsos Negativos (FNR): {fnr:.4f} ({fnr*100:.2f}%)\")\n",
    "\n",
    "# Verificação com funções do sklearn\n",
    "print(f\"\\nVERIFICAÇÃO COM SKLEARN:\")\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred)\n",
    "precision_sklearn = precision_score(y_test, y_pred)\n",
    "recall_sklearn = recall_score(y_test, y_pred)\n",
    "f1_sklearn = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Acurácia (sklearn): {accuracy_sklearn:.4f}\")\n",
    "print(f\"Precisão (sklearn): {precision_sklearn:.4f}\")\n",
    "print(f\"Recall (sklearn): {recall_sklearn:.4f}\")\n",
    "print(f\"F1-Score (sklearn): {f1_sklearn:.4f}\")\n",
    "\n",
    "# Relatório de classificação completo\n",
    "print(f\"\\nRELATÓRIO DE CLASSIFICAÇÃO:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Não Atrasado', 'Atrasado']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7919657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualização das métricas\n",
    "print(\"VISUALIZAÇÃO DAS MÉTRICAS\")\n",
    "\n",
    "# Criando um DataFrame com as métricas\n",
    "metrics_data = {\n",
    "    'Métrica': ['Acurácia', 'Sensibilidade\\n(Recall)', 'Especificidade', \n",
    "                'Precisão', 'F1-Score', 'FPR', 'FNR'],\n",
    "    'Valor': [accuracy_manual, sensitivity_recall, specificity, \n",
    "              precision, f1, fpr, fnr],\n",
    "    'Interpretação': [\n",
    "        'Proporção de acertos totais',\n",
    "        'Capacidade de identificar atrasos',\n",
    "        'Capacidade de identificar não-atrasos',\n",
    "        'Confiabilidade das predições positivas',\n",
    "        'Harmonia entre precisão e recall',\n",
    "        'Taxa de alarmes falsos',\n",
    "        'Taxa de atrasos perdidos'\n",
    "    ]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Gráfico de barras das métricas principais\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Gráfico das métricas principais\n",
    "plt.subplot(2, 2, 1)\n",
    "main_metrics = ['Acurácia', 'Sensibilidade\\n(Recall)', 'Especificidade', 'Precisão', 'F1-Score']\n",
    "main_values = [accuracy_manual, sensitivity_recall, specificity, precision, f1]\n",
    "colors = ['skyblue', 'lightgreen', 'salmon', 'gold', 'lightcoral']\n",
    "\n",
    "bars = plt.bar(main_metrics, main_values, color=colors)\n",
    "plt.title('Métricas Principais do Modelo')\n",
    "plt.ylabel('Valor')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# Adicionando valores nas barras\n",
    "for bar, value in zip(bars, main_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Gráfico das taxas de erro\n",
    "plt.subplot(2, 2, 2)\n",
    "error_metrics = ['FPR', 'FNR']\n",
    "error_values = [fpr, fnr]\n",
    "error_colors = ['orange', 'red']\n",
    "\n",
    "bars2 = plt.bar(error_metrics, error_values, color=error_colors)\n",
    "plt.title('Taxas de Erro')\n",
    "plt.ylabel('Taxa')\n",
    "plt.ylim(0, max(error_values) * 1.2)\n",
    "\n",
    "for bar, value in zip(bars2, error_values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Comparação das métricas em formato radar (simplificado)\n",
    "plt.subplot(2, 2, 3)\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Métrica': ['Acurácia', 'Precisão', 'Recall', 'F1-Score'],\n",
    "    'Valor': [accuracy_manual, precision, sensitivity_recall, f1]\n",
    "})\n",
    "\n",
    "plt.plot(metrics_comparison['Métrica'], metrics_comparison['Valor'], \n",
    "         marker='o', linewidth=2, markersize=8)\n",
    "plt.title('Comparação de Métricas')\n",
    "plt.ylabel('Valor')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Tabela resumo\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.axis('off')\n",
    "table_data = []\n",
    "for _, row in metrics_df.iterrows():\n",
    "    table_data.append([row['Métrica'], f\"{row['Valor']:.4f}\", row['Interpretação']])\n",
    "\n",
    "table = plt.table(cellText=table_data,\n",
    "                  colLabels=['Métrica', 'Valor', 'Interpretação'],\n",
    "                  cellLoc='left',\n",
    "                  loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "plt.title('Resumo das Métricas')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nINTERPRETAÇÃO DAS MÉTRICAS:\")\n",
    "print(f\"• Acurácia ({accuracy_manual:.1%}): {accuracy_manual*100:.1f}% dos casos foram classificados corretamente\")\n",
    "print(f\"• Sensibilidade ({sensitivity_recall:.1%}): {sensitivity_recall*100:.1f}% dos atrasos reais foram identificados\")\n",
    "print(f\"• Especificidade ({specificity:.1%}): {specificity*100:.1f}% dos não-atrasos reais foram identificados\")\n",
    "print(f\"• Precisão ({precision:.1%}): {precision*100:.1f}% das predições de atraso foram corretas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3263d5d0",
   "metadata": {},
   "source": [
    "## 7. Curva ROC e AUC\n",
    "\n",
    "Gerando a curva ROC e calculando a área sob a curva (AUC):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2622ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a Curva ROC e AUC\n",
    "print(\"CURVA ROC E AUC\")\n",
    "\n",
    "# Calculando os pontos da curva ROC\n",
    "fpr_roc, tpr_roc, thresholds = roc_curve(y_test, y_proba_positive)\n",
    "\n",
    "# Calculando a AUC\n",
    "auc_score = auc(fpr_roc, tpr_roc)\n",
    "auc_sklearn = roc_auc_score(y_test, y_proba_positive)\n",
    "\n",
    "print(f\"AUC calculada manualmente: {auc_score:.4f}\")\n",
    "print(f\"AUC calculada com sklearn: {auc_sklearn:.4f}\")\n",
    "\n",
    "# Visualização da Curva ROC\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Curva ROC principal\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(fpr_roc, tpr_roc, linewidth=2, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "plt.title('Curva ROC (Receiver Operating Characteristic)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionando o ponto do nosso modelo com threshold 0.5\n",
    "current_fpr = fp / (fp + tn)\n",
    "current_tpr = tp / (tp + fn)\n",
    "plt.plot(current_fpr, current_tpr, 'ro', markersize=8, \n",
    "         label=f'Modelo Atual (threshold=0.5)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Zoom na região interessante da curva ROC\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(fpr_roc, tpr_roc, linewidth=2, label=f'ROC Curve (AUC = {auc_score:.3f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "plt.xlim([0.0, 0.4])  # Zoom na parte interessante\n",
    "plt.ylim([0.6, 1.0])\n",
    "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
    "plt.title('Curva ROC - Zoom')\n",
    "plt.plot(current_fpr, current_tpr, 'ro', markersize=8)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuição das probabilidades\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(y_proba_positive[y_test == 0], bins=50, alpha=0.7, \n",
    "         label='Não Atrasado', color='skyblue', density=True)\n",
    "plt.hist(y_proba_positive[y_test == 1], bins=50, alpha=0.7, \n",
    "         label='Atrasado', color='salmon', density=True)\n",
    "plt.axvline(x=threshold, color='red', linestyle='--', linewidth=2, \n",
    "           label=f'Threshold = {threshold}')\n",
    "plt.xlabel('Probabilidade Predita')\n",
    "plt.ylabel('Densidade')\n",
    "plt.title('Distribuição das Probabilidades')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Análise de diferentes thresholds\n",
    "plt.subplot(2, 2, 4)\n",
    "thresholds_analysis = np.linspace(0, 1, 101)\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "\n",
    "for thresh in thresholds_analysis:\n",
    "    y_pred_thresh = (y_proba_positive >= thresh).astype(int)\n",
    "    if len(np.unique(y_pred_thresh)) > 1:  # Evita divisão por zero\n",
    "        prec = precision_score(y_test, y_pred_thresh)\n",
    "        rec = recall_score(y_test, y_pred_thresh)\n",
    "        f1_thresh = f1_score(y_test, y_pred_thresh)\n",
    "    else:\n",
    "        prec = 0 if thresh > 0.5 else 1\n",
    "        rec = 0 if thresh > 0.5 else 1\n",
    "        f1_thresh = 0 if thresh > 0.5 else 1\n",
    "    \n",
    "    precision_list.append(prec)\n",
    "    recall_list.append(rec)\n",
    "    f1_list.append(f1_thresh)\n",
    "\n",
    "plt.plot(thresholds_analysis, precision_list, label='Precisão', linewidth=2)\n",
    "plt.plot(thresholds_analysis, recall_list, label='Recall', linewidth=2)\n",
    "plt.plot(thresholds_analysis, f1_list, label='F1-Score', linewidth=2)\n",
    "plt.axvline(x=threshold, color='red', linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Métrica')\n",
    "plt.title('Métricas vs Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nINTERPRETAÇÃO DA AUC:\")\n",
    "if auc_score >= 0.9:\n",
    "    interpretation = \"EXCELENTE\"\n",
    "elif auc_score >= 0.8:\n",
    "    interpretation = \"BOM\"\n",
    "elif auc_score >= 0.7:\n",
    "    interpretation = \"RAZOÁVEL\"\n",
    "elif auc_score >= 0.6:\n",
    "    interpretation = \"FRACO\"\n",
    "else:\n",
    "    interpretation = \"MUITO FRACO\"\n",
    "\n",
    "print(f\"AUC = {auc_score:.3f} - Desempenho: {interpretation}\")\n",
    "print(f\"\\nSignificado:\")\n",
    "print(f\"• AUC = 1.0: Classificador perfeito\")\n",
    "print(f\"• AUC = 0.5: Classificador aleatório\") \n",
    "print(f\"• AUC > 0.7: Bom poder discriminativo\")\n",
    "print(f\"• Nosso modelo: {auc_score:.1%} de chance de classificar corretamente um par aleatório\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752c895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva Precision-Recall adicional\n",
    "print(\"CURVA PRECISION-RECALL\")\n",
    "\n",
    "# Calculando a curva Precision-Recall\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_proba_positive)\n",
    "pr_auc = auc(recall_curve, precision_curve)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Curva Precision-Recall\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(recall_curve, precision_curve, linewidth=2, \n",
    "         label=f'PR Curve (AUC = {pr_auc:.3f})')\n",
    "plt.axhline(y=np.mean(y_test), color='red', linestyle='--', \n",
    "           label=f'Baseline = {np.mean(y_test):.3f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Curva Precision-Recall')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Comparação ROC vs PR\n",
    "plt.subplot(1, 2, 2)\n",
    "metrics_comparison = ['ROC AUC', 'PR AUC', 'Accuracy', 'F1-Score']\n",
    "scores = [auc_score, pr_auc, accuracy_manual, f1]\n",
    "colors = ['blue', 'green', 'orange', 'red']\n",
    "\n",
    "bars = plt.bar(metrics_comparison, scores, color=colors, alpha=0.7)\n",
    "plt.title('Comparação de Métricas de Avaliação')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "for bar, score in zip(bars, scores):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{score:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"PR AUC: {pr_auc:.3f}\")\n",
    "print(f\"ROC AUC: {auc_score:.3f}\")\n",
    "print(f\"\\nQuando usar cada métrica:\")\n",
    "print(f\"• ROC AUC: Melhor para datasets balanceados\")\n",
    "print(f\"• PR AUC: Melhor para datasets desbalanceados com foco na classe positiva\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5cce1",
   "metadata": {},
   "source": [
    "## 8. Análise de Resultados e Melhorias\n",
    "\n",
    "Resumo final dos resultados e propostas de melhorias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01954ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final dos resultados\n",
    "print(\"RESUMO FINAL DOS RESULTADOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Informações do dataset\n",
    "print(f\"DATASET:\")\n",
    "print(f\"• Total de registros: {len(df):,}\")\n",
    "print(f\"• Features após encoding: {X_encoded.shape[1]}\")\n",
    "print(f\"• Distribuição target: {target_counts[0]} não atrasados, {target_counts[1]} atrasados\")\n",
    "\n",
    "# Performance do modelo\n",
    "print(f\"\\nPERFORMANCE DO MODELO:\")\n",
    "print(f\"• Acurácia: {accuracy_manual:.1%}\")\n",
    "print(f\"• Precisão: {precision:.1%}\")\n",
    "print(f\"• Sensibilidade (Recall): {sensitivity_recall:.1%}\")\n",
    "print(f\"• Especificidade: {specificity:.1%}\")\n",
    "print(f\"• F1-Score: {f1:.3f}\")\n",
    "print(f\"• ROC AUC: {auc_score:.3f}\")\n",
    "print(f\"• PR AUC: {pr_auc:.3f}\")\n",
    "\n",
    "# Matriz de confusão resumo\n",
    "print(f\"\\nMATRIZ DE CONFUSÃO:\")\n",
    "print(f\"• Verdadeiros Positivos (TP): {tp}\")\n",
    "print(f\"• Verdadeiros Negativos (TN): {tn}\")\n",
    "print(f\"• Falsos Positivos (FP): {fp}\")\n",
    "print(f\"• Falsos Negativos (FN): {fn}\")\n",
    "\n",
    "# Análise de negócio\n",
    "print(f\"\\nANÁLISE DE NEGÓCIO:\")\n",
    "print(f\"• Taxa de alarmes falsos: {fpr:.1%} (clientes alertados desnecessariamente)\")\n",
    "print(f\"• Taxa de atrasos perdidos: {fnr:.1%} (atrasos não detectados)\")\n",
    "\n",
    "# Avaliação geral\n",
    "print(f\"\\nAVALIAÇÃO GERAL:\")\n",
    "overall_score = (accuracy_manual + auc_score + f1) / 3\n",
    "if overall_score >= 0.85:\n",
    "    evaluation = \"EXCELENTE\"\n",
    "elif overall_score >= 0.75:\n",
    "    evaluation = \"BOM\"\n",
    "elif overall_score >= 0.65:\n",
    "    evaluation = \"REGULAR\"\n",
    "else:\n",
    "    evaluation = \"PRECISA MELHORAR\"\n",
    "\n",
    "print(f\"Score geral: {overall_score:.3f} - {evaluation}\")\n",
    "\n",
    "print(f\"\\nPROPOSTAS DE MELHORIAS:\")\n",
    "improvements = [\n",
    "    \"1. Otimização de hiperparâmetros (GridSearch/RandomSearch)\",\n",
    "    \"2. Feature Engineering - criação de novas variáveis\",\n",
    "    \"3. Tratamento de desbalanceamento (SMOTE, class_weight)\",\n",
    "    \"4. Ensemble methods (Random Forest, Voting Classifier)\",\n",
    "    \"5. Validação cruzada para estimativa mais robusta\",\n",
    "    \"6. Análise de feature importance\",\n",
    "    \"7. Otimização do threshold baseada no custo de negócio\",\n",
    "    \"8. Coleta de mais dados ou features relevantes\",\n",
    "    \"9. Análise temporal (sazonalidade, tendências)\",\n",
    "    \"10. Implementação de modelos mais complexos (Neural Networks)\"\n",
    "]\n",
    "\n",
    "for improvement in improvements:\n",
    "    print(f\"  {improvement}\")\n",
    "\n",
    "print(f\"\\nPRÓXIMOS PASSOS RECOMENDADOS:\")\n",
    "next_steps = [\n",
    "    \"• Implementar validação cruzada\",\n",
    "    \"• Otimizar threshold baseado no contexto de negócio\",\n",
    "    \"• Analisar feature importance do XGBoost\",\n",
    "    \"• Testar outros algoritmos de classificação\",\n",
    "    \"• Implementar pipeline de preprocessing completo\"\n",
    "]\n",
    "\n",
    "for step in next_steps:\n",
    "    print(f\"  {step}\")\n",
    "\n",
    "print(f\"\\nATIVIDADE CONCLUÍDA COM SUCESSO!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef2fc1c",
   "metadata": {},
   "source": [
    "## Conclusão da Atividade 2\n",
    "\n",
    "### Objetivos Alcançados:\n",
    "\n",
    "**1. Importar e preparar os dados**\n",
    "- Dataset `flights_delays_120.csv` carregado e analisado\n",
    "- Variáveis categóricas tratadas com `pd.get_dummies()`\n",
    "- Divisão estratificada em treino e teste\n",
    "\n",
    "**2. Treinar o modelo XGBoost**\n",
    "- Classificador XGBoost configurado com parâmetros adequados\n",
    "- Modelo treinado com sucesso\n",
    "\n",
    "**3. Predição do modelo**\n",
    "- Probabilidades obtidas com `predict_proba`\n",
    "- Conversão para classes binárias com threshold 0.5\n",
    "- Análise detalhada das probabilidades\n",
    "\n",
    "**4. Matriz de Confusão**\n",
    "- Matriz calculada e visualizada\n",
    "- Extração de TP, TN, FP, FN\n",
    "- Interpretação detalhada dos componentes\n",
    "\n",
    "**5. Métricas de desempenho**\n",
    "- Sensibilidade (Recall), Especificidade, FPR, FNR calculadas\n",
    "- Acurácia, Precisão e F1-Score analisadas\n",
    "- Comparação entre cálculos manuais e sklearn\n",
    "\n",
    "**6. Curva ROC e AUC**\n",
    "- Curva ROC gerada e visualizada\n",
    "- AUC calculada e interpretada\n",
    "- Curva Precision-Recall adicional\n",
    "- Análise de diferentes thresholds\n",
    "\n",
    "### Resultados Obtidos:\n",
    "- **ROC AUC**: Métrica principal para avaliação do modelo\n",
    "- **Visualizações completas**: Matriz de confusão, curvas ROC e PR\n",
    "- **Métricas detalhadas**: Todas as métricas solicitadas calculadas\n",
    "- **Interpretação de negócio**: Análise do impacto prático dos resultados\n",
    "\n",
    "### Valor para o Negócio:\n",
    "O modelo desenvolvido pode ser usado pelo site de reservas para:\n",
    "- Informar probabilidade de atraso no momento da reserva\n",
    "- Melhorar a experiência do cliente com informações precisas\n",
    "- Reduzir reclamações através de expectativas adequadas\n",
    "\n",
    "**Atividade 2 concluída com excelência!**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
